[
{
	"uri": "/_header/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "trvoid\n"
},
{
	"uri": "/ble/ble01-intro/",
	"title": "BLE01 - Introduction",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/ble/ble02-physical-layer/",
	"title": "BLE02 - Physical layer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/ble/",
	"title": "Bluetooth Low Energy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/",
	"title": "Home",
	"tags": [],
	"description": "",
	"content": " trvoid 기술 문서 작성을 위한 소프트웨어 개발자의 웹사이트\n문서 작성 원칙  한글 사용자를 위한 문서를 작성합니다. 이론과 실무를 균형있게 다룹니다. 타인의 지식을 존중합니다.  "
},
{
	"uri": "/web/web01-hugo-docdock-github/",
	"title": "Hugo + DocDock 웹사이트를 GitHub Pages로 호스팅하기",
	"tags": [],
	"description": "",
	"content": " Hugo 프레임워크에 DocDock 테마를 추가하여 정적 웹사이트를 만들고 이를 GitHub 저장소에 올려서 GitHub Pages로 호스팅하는 과정을 정리하였습니다.\n1 제품 소개 1.1 Hugo  정적 웹사이트를 생성하는 도구. Go 언어로 개발함.  1.2 DocDock  기술 문서 작성을 위한 Hugo용 테마. Learn 테마를 기반으로 함.  1.3 GitHub Pages  정적 웹사이트 호스팅 서비스를 무료로 제공. GitHub 저장소와 직접 연결. 개인, 조직, 프로젝트 유형에 따른 페이지 제공. 사이트 저장 용량은 최대 1GB.  2 Hugo와 DocDock 설치 다음과 같은 환경에서 설치를 진행하고 이 문서를 작성하였습니다.\n 프로세서: Intel Core i5 (x64 기반) 운영체제: Windows 10 (64 비트)  2.1 Hugo 설치 1) Hugo Releases 페이지에서 다음 파일을 다운로드하고 압축을 풉니다.\nhugo_0.25.1_Windows-64bit.zip  2) 압축을 푼 폴더를 환경 변수 PATH에 추가하고 사이트를 생성하고자 하는 폴더에서 명령창을 엽니다.\n3) 다음과 같이 명령을 실행하여 새 Hugo 사이트를 생성합니다.\nC:\\DevApps\\hugo_0.25.1_Windows-64bit\u0026gt;hugo new site quickstart Congratulations! Your new Hugo site is created in C:\\DevApps\\hugo_0.25.1_Windows-64bit\\quickstart. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/, or create your own with the \u0026quot;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026quot; command. 2. Perhaps you want to add some content. You can add single files with \u0026quot;hugo new \u0026lt;SECTIONNAME\u0026gt;\\\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026quot;. 3. Start the built-in live server via \u0026quot;hugo server\u0026quot;. Visit https://gohugo.io/ for quickstart guide and full documentation.  위 명령은 quickstart 폴더에 새 사이트를 만듭니다.\n4) 위에서 생성한 Hugo 사이트 폴더를 Git 저장소로 만듭니다.\n\u0026gt; cd quickstart \u0026gt; git init  이후부터 본문에서 언급하는 폴더들과 명령창에서 실행하는 명령들의 기준 위치는 quickstart 폴더입니다.\n2.2 테마 DocDock 추가 1) Hugo 테마 DocDock을 themes/dockdock 폴더에 추가합니다.\n\u0026gt; git submodule add https://github.com/vjeantet/hugo-theme-docdock.git themes/docdock  2) 테마 DocDock을 사용하도록 config.toml 파일에 다음 한 줄을 추가합니다.\ntheme = \u0026quot;docdock\u0026quot;  3 컨텐츠 생성 컨텐츠는 content 폴더 아래에서 Markdown 문법을 사용하여 작성합니다. 폴더의 계층 구조는 웹사이트 좌측 메뉴바의 계층 구조로 나타납니다. 또한 각 폴더의 _index.md 파일에서 작성한 내용은 해당 폴더의 주 화면에 표시됩니다.\n3.1 컨텐츠 파일 작성 실습을 위하여 content 폴더 아래에 다음 파일들을 만들고 제시한 내용들을 저장합니다.\n _header.md\n화면 좌측 상단에 표시할 문구를 작성합니다.\nQuickStart  _index.md\n홈 화면에서 표시할 문서를 작성합니다.\n--- Title: \u0026quot;Home\u0026quot; --- # Home  ble/_index.md\nble 폴더의 주 화면에서 표시할 문서를 작성합니다.\n--- Title: \u0026quot;Bluetooth Low Energy\u0026quot; ---  ble/ble01-intro.md\nble 폴더의 하위 메뉴로 표시할 문서를 작성합니다.\n--- Title: \u0026quot;BLE01 - Introduction\u0026quot; ---  ble/ble02-physical-layer.md\nble 폴더의 하위 메뉴로 표시할 문서를 작성합니다.\n--- Title: \u0026quot;BLE02 - Physical layer\u0026quot; ---  ml/_index.md\nml 폴더의 주 화면에서 표시할 문서를 작성합니다.\n--- Title: \u0026quot;Machine Learning\u0026quot; ---  ml/ml01-intro.md\nml 폴더의 하위 메뉴로 표시할 문서를 작성합니다.\n--- Title: \u0026quot;ML01 - Introduction\u0026quot; ---  ml/ml02-linear-regression.md\nml 폴더의 하위 메뉴로 표시할 문서를 작성합니다.\n--- Title: \u0026quot;ML02 - Linear regression\u0026quot; ---   3.2 개발 서버로 웹사이트 검증 1) Hugo 개발 서버를 실행합니다.\n\u0026gt; hugo server  2) 브라우져로 아래 주소에 연결합니다.\nhttp://localhost:1313  3) 화면 왼쪽 사이드바에 메뉴가 나타나고 각각의 메뉴 항목을 클릭하여 위에서 작성한 모든 컨텐츠를 볼 수 있는지 확인합니다.\n4 컨텐츠 배치 content 폴더 아래에서 작성한 컨텐츠를 GitHub Pages 서비스를 통해서 호스팅하려면 먼저 배치용 컨텐츠로 변환해야 합니다. 변환 결과는 public 폴더 아래에 저장되고 public 폴더 아래의 내용을 GitHub 저장소에 올리면 바로 웹으로 서비스됩니다. GitHub 계정의 사용자 이름이 yourname 이라고 하면 GitHub 저장소 주소와 여기에 연결된 웹사이트 주소는 다음과 같습니다.\nGitHub 저장소 주소:\nhttps://github.com/yourname/yourname.github.io.git  GitHub Pages 웹사이트 주소:\nhttps://yourname.github.io  4.1 설정 config.toml 파일을 열고 baseURL 항목의 값을 /로 지정합니다.\nbaseURL = \u0026quot;/\u0026quot; languageCode = \u0026quot;en-us\u0026quot; title = \u0026quot;QuickStart\u0026quot; theme = \u0026quot;docdock\u0026quot;  4.2 GitHub 저장소를 서브모듈로 추가 GitHub의 웹사이트 저장소를 서브모듈로 public 폴더 아래에 추가합니다.\n\u0026gt; git submodule add https://github.com/yourname/yourname.github.io.git public  4.3 컨텐츠를 배치용으로 변환 아래와 같이 명령을 실행하여 배치용 컨텐츠로 변환합니다.\n\u0026gt; hugo  위 명령이 끝나면 public 폴더에서 배치용 컨텐츠를 찾을 수 있습니다.\n4.4 컨텐츠를 GitHub에 배치 1) public 폴더의 변경 사항을 commit하고 push하면 GitHub 저장소에 반영됩니다.\n2) 브라우져를 열고 다음 주소에 연결합니다\nhttps://yourname.github.io  3) 화면 왼쪽 사이드바에 메뉴가 나타나고 각각의 메뉴 항목을 클릭하여 위에서 작성한 모든 컨텐츠를 볼 수 있는지 확인합니다.\n참고 자료  Hugo Quick Start Hugo Themes How To Install and Use Hugo, a Static Site Generator, on Ubuntu 14.04 What is GitHub Pages? Host on GitHub  "
},
{
	"uri": "/ml/ml01-intro/",
	"title": "ML01 - Introduction",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/ml/ml02-linear-regression/",
	"title": "ML02 - 선형 회귀",
	"tags": [],
	"description": "",
	"content": " 1 소개 회귀 분석 과정을 다음 세 단계로 간단하게 정리할 수 있습니다.\n 훈련 데이터 세트 (x, y)를 준비합니다. 여기서 x는 독립 변수, y는 종속 변수입니다. 훈련 데이터 세트를 표현할 수 있는 모델을 만들고 가장 근접한 결과를 보여 주는 파라미터를 찾습니다. 새로운 데이터의 x값이 주어질 때 앞에서 얻은 모델을 사용하여 y값을 예측합니다.  모델을 만들 때 종속 변수 y를 독립 변수 x의 일차식으로 표현하면 이를 선형 회귀라고 말합니다. 그리고 x가 하나의 변수이면 일변량 선형 회귀, 둘 이상의 변수이면 다변량 선형 회귀라고 합니다.\n이 문서를 작성하면서 사용하는 주요 용어들은 다음과 같습니다.\n hypothesis - 모델을 나타내는 함수 식 feature - 독립 변수 x의 개별 요소 cost function - 훈련 데이터 세트의 종속 변수 y와 모델의 예측값의 차이를 나타내는 함수 식  2 일변량 선형 회귀 2.1 Hypothesis와 cost function 훈련 데이터의 feature가 한 개일 때 hypothesis는 다음과 같이 표현할 수 있습니다.\n$$ { h }_{ \\theta }(x)={ \\theta }_{ 0 }+{ \\theta }_{ 1 }{ x }_{ 1 } $$ 위의 식에서 \\(x\\)는 데이터의 feature들이고 \\(\\theta\\)는 찾고자 하는 파라미터들입니다. \\(x_0=1\\)라고 하면 위의 식을 다음과 같은 형태로 표현할 수 있습니다.\n$$ h_\\theta(x)=x^T\\cdot\\theta $$ $$ x=(x_0,x_1), \\theta=(\\theta_0,\\theta_1) $$ 데이터의 개수가 \\(m\\)일 때 cost function은 다음과 같이 표현할 수 있습니다. \\(y\\)는 데이터의 결과값이고 \\((i)\\)는 \\(i\\)번째 데이터임을 의미합니다.\n$$ J(\\theta )=\\frac { 1 }{ 2m } \\sum _{ i=1 }^{ m }{ { \\left( { h }_{ \\theta }({ x }^{ (i) })-{ y }^{ (i) } \\right) }^{ 2 } } $$ hypothesis를 대입하여 위 식을 전개하면 cost function은 각각의 파라미터에 대하여 아래로 볼록한 2차 함수가 됩니다.\n$$ J(\\theta )=\\frac { 1 }{ 2m } \\sum _{ i=1 }^{ m }{ \\left( { \\theta }_{ 0 }^{ 2 }+{ \\theta }_{ 1 }^{ 2 }{ x }_{ 1 }^{ (i)2 }+{ y }_{ }^{ (i)2 }+2{ \\theta }_{ 0 }{ \\theta }_{ 1 }{ x }_{ 1 }^{ (i) }-2{ \\theta }_{ 1 }{ x }_{ 1 }^{ (i) }{ y }_{ }^{ (i) }-2{ y }_{ }^{ (i) }{ \\theta }_{ 0 } \\right) } $$ 이 cost function이 최소값을 가지도록 하는 파라미터 \\(\\theta\\)를 찾는 방법은 3 다변량 선형 회귀 단원에서 다루겠습니다.\n3 다변량 선형 회귀 3.1 Hypothesis와 cost function 훈련 데이터의 feature가 \\(n\\)개일 때 hypothesis는 다음과 같이 표현할 수 있습니다. \\(x\\)는 데이터의 feature들이고 \\(\\theta\\)는 찾고자 하는 파라미터들입니다.\n$$ { h }_{ \\theta }(x)={ \\theta }_{ 0 }+{ \\theta }_{ 1 }{ x }_{ 1 }+{ \\theta }_{ 2 }{ x }_{ 2 }+\\cdots +{ \\theta }_{ n }{ x }_{ n } $$ 데이터의 개수가 \\(m\\)일 때 cost function은 다음과 같이 표현할 수 있습니다. \\(y\\)는 데이터의 결과값이고 \\((i)\\)는 \\(i\\)번째 데이터임을 의미합니다.\n$$ J(\\theta )=\\frac { 1 }{ 2m } \\sum _{ i=1 }^{ m }{ { \\left( { h }_{ \\theta }({ x }^{ (i) })-{ y }^{ (i) } \\right) }^{ 2 } } $$ 3.2 Gradient descent cost function의 편미분을 사용하여 cost를 최소화하는 파라미터 $\\theta$를 찾을 수 있습니다. 다음은 gradient descent 방식을 나타내는 알고리즘입니다.\n$$ repeat \\quad \\{ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad\\\\ { \\theta }_{ j }:={ \\theta }_{ j }-\\alpha \\frac { \\partial J(\\theta ) }{ \\partial { \\theta }_{ j } } \\\\ \\} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad $$ $$ \\frac { \\partial J(\\theta ) }{ \\partial { \\theta }_{ j } } =\\frac { 1 }{ m } \\sum _{ i=1 }^{ m }{ \\left( { h }_{ \\theta }({ x }^{ (i) })-{ y }^{ (i) } \\right) { { x }_{ j } }^{ (i) } } $$ 위의 식에서 $\\alpha$는 학습률(learning rate)입니다.\n3.3 방정식의 해 아래로 볼록한 함수의 경우 기울기가 $0$일 때 최소값을 가지므로 다음 방정식을 풀어서 cost를 최소가 되게 하는 $\\theta$를 구할 수도 있습니다.\n$$ \\frac { \\partial J(\\theta ) }{ \\partial { \\theta }_{ j } } =\\frac { 1 }{ m } \\sum _{ i=1 }^{ m }{ \\left( { h }_{ \\theta }({ x }^{ (i) })-{ y }^{ (i) } \\right) { { x }_{ j } }^{ (i) } } = 0 $$ 위 방정식을 $\\theta$에 대해서 풀면 아래의 결과를 얻습니다.\n$$ \\theta ={ \\left( { X }^{ T }\\cdot X \\right) }^{ -1 }\\cdot { X }^{ T }\\cdot y $$ 여기서 $X$와 $y$는 다음과 같습니다.\n$$ X=\\begin{bmatrix} { x }_{ 0 }^{ (1) } \u0026 { x }_{ 1 }^{ (1) } \u0026 { x }_{ 2 }^{ (1) } \u0026 \\cdots \\\\ { x }_{ 0 }^{ (2) } \u0026 { x }_{ 1 }^{ (2) } \u0026 { x }_{ 2 }^{ (2) } \u0026 \\cdots \\\\ { x }_{ 0 }^{ (3) } \u0026 { x }_{ 1 }^{ (3) } \u0026 { x }_{ 2 }^{ (3) } \u0026 \\cdots \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \\end{bmatrix}, \\quad y=\\begin{bmatrix} { y }^{ (1) } \\\\ { y }^{ (2) } \\\\ { y }^{ (3) } \\\\ \\vdots \\end{bmatrix} $$ 하지만 이 방식은 몇 가지 단점을 가지고 있습니다.\n 행렬 ${ { X }^{ T }\\cdot X }$에 대한 역행렬이 존재하지 않을 수도 있습니다. $n$이 커짐에 따라 계산 비용이 gradient descent 방식보다 빠른 속도로 증가합니다.  "
},
{
	"uri": "/ml/ml03-logistic-regression/",
	"title": "ML03 - 로지스틱 회귀",
	"tags": [],
	"description": "",
	"content": " 1 소개 1.1 시그모이드 함수와 로지스틱 함수 아래 수식에 따르면 시그모이드 함수는 로지스틱 함수의 특별한 경우에 해당합니다.\n로지스틱 함수:\n$$f(x)=\\frac { L }{ 1+{ e }^{ -k(x-{ x }_{ 0 }) } } $$\n시그모이드 함수:\n$$s(x)=\\frac { 1 }{ 1+{ e }^{-x} } $$\n3 참고 자료 "
},
{
	"uri": "/ml/",
	"title": "Machine Learning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/web/",
	"title": "Web",
	"tags": [],
	"description": "",
	"content": ""
}]