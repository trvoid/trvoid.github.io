<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="generator" content="Hugo 0.25.1" />
    <meta name="description" content="">


    <title>ML03 - 로지스틱 회귀 :: trvoid</title>
    <link rel="shortcut icon" href="/images/favicon.png" type="image/x-icon" />
    <link href="/css/nucleus.css" rel="stylesheet">
    <link href="/css/font-awesome.min.css" rel="stylesheet">
    <link href="/css/hybrid.css" rel="stylesheet">
    <link href="/css/featherlight.min.css" rel="stylesheet">
    <link href="/css/horsey.css" rel="stylesheet">
    
    <link href="/css/theme.css" rel="stylesheet">
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <script src="/js/jquery-2.x.min.js"></script>
    <style type="text/css">
      :root #header + #content > #left > #rlblock_left {
        display:none !important;
      }
    </style>

    

    

  </head>
  <body class="" data-url="/ml/ml03-logistic-regression/">
    <nav id="sidebar" class="">





<div class="highlightable">
  <div id="header-wrapper">
    <div id="header">
       
	<p>trvoid</p>
 


    </div>
    
        <div class="searchbox">
    <label for="search-by"><i class="fa fa-search"></i></label>
    <input data-search-input id="search-by" type="text" placeholder="Search...">
    <span data-search-clear=""><i class="fa fa-close"></i></span>
</div>
<script type="text/javascript" src="/js/lunr.min.js"></script>
<script type="text/javascript" src="/js/horsey.js"></script>
<script type="text/javascript">
    var baseurl = "\/";
</script>
<script type="text/javascript" src="/js/search.js"></script>

    
  </div>

  
    <ul class="topics">
        
            <li data-nav-id="/" class="dd-item">
            <a href="/"><i class="fa fa-fw fa-home"></i></a>
            </li>
        
        
        
          
          


 
  
    
    <li data-nav-id="/ble/" class="dd-item 
        
        
        
        ">
      <a href="/ble/">
        <span>Bluetooth Low Energy</span>

        
        

          
            <i class="fa fa-angle-right fa-lg category-icon"></i>
          

        

        
      </a>
      
        <ul>
          
          
          
          
        
          
            
            


 
  
    
      <li data-nav-id="/ble/ble01-intro/" class="dd-item
     
      ">
        <a href="/ble/ble01-intro/">
        <span>BLE01 - Introduction</span> 
        
        </a></li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ble/ble02-physical-layer/" class="dd-item
     
      ">
        <a href="/ble/ble02-physical-layer/">
        <span>BLE02 - Physical layer</span> 
        
        </a></li>
     
  
 

            
          
        
        </ul>
              
    </li>
  
 

          
          


 
  
    
    <li data-nav-id="/ml/" class="dd-item 
        parent
        
        
        ">
      <a href="/ml/">
        <span>Machine Learning</span>

        
        

          
            <i class="fa fa-angle-down fa-lg category-icon"></i>
          

        

        
      </a>
      
        <ul>
          
          
          
          
        
          
            
            


 
  
    
      <li data-nav-id="/ml/ml01-intro/" class="dd-item
     
      ">
        <a href="/ml/ml01-intro/">
        <span>ML01 - Introduction</span> 
        
        </a></li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ml/ml02-linear-regression/" class="dd-item
     
      ">
        <a href="/ml/ml02-linear-regression/">
        <span>ML02 - 선형 회귀</span> 
        
        </a></li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ml/ml03-logistic-regression/" class="dd-item
     active
      ">
        <a href="/ml/ml03-logistic-regression/">
        <span>ML03 - 로지스틱 회귀</span> 
        
        </a></li>
     
  
 

            
          
        
        </ul>
              
    </li>
  
 

          
          


 
  
    
    <li data-nav-id="/web/" class="dd-item 
        
        
        
        ">
      <a href="/web/">
        <span>Web</span>

        
        

          
            <i class="fa fa-angle-right fa-lg category-icon"></i>
          

        

        
      </a>
      
        <ul>
          
          
          
          
        
          
            
            


 
  
    
      <li data-nav-id="/web/web01-hugo-docdock-github/" class="dd-item
     
      ">
        <a href="/web/web01-hugo-docdock-github/">
        <span>Hugo &#43; DocDock 웹사이트를 GitHub Pages로 호스팅하기</span> 
        
        </a></li>
     
  
 

            
          
        
        </ul>
              
    </li>
  
 

          
        

        
    </ul>
    
     
    <section id="footer">
      
    </section>
  </div>
</nav>




        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
        
          <div id="top-bar">
            

            <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                <span id="sidebar-toggle-span">
                  <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                    <i class="fa fa-bars"></i>
                  </a>
                </span>
                <span id="toc-menu"><i class="fa fa-list-alt"></i></span>
                <span class="links">
                







 <a href='/'>Home</a> > <a href='/ml/'>Machine Learning</a> > ML03 - 로지스틱 회귀

 

 

   
                </span>
            </div>
            <div class="progress">
    <div class="wrapper">
<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#1-문제를-정의하기">1 문제를 정의하기</a>
<ul>
<li><a href="#1-1-데이터-세트">1.1 데이터 세트</a></li>
<li><a href="#1-2-단계별로-과제-해결">1.2 단계별로 과제 해결</a></li>
</ul></li>
<li><a href="#2-hypothesis-찾기">2 Hypothesis 찾기</a>
<ul>
<li><a href="#2-1-첫번째-시도">2.1 첫번째 시도</a></li>
<li><a href="#2-2-두번째-시도">2.2 두번째 시도</a></li>
<li><a href="#2-3-세번째-시도">2.3 세번째 시도</a></li>
</ul></li>
<li><a href="#3-cost-function-정의하기">3 Cost function 정의하기</a>
<ul>
<li><a href="#3-1-첫번째-시도">3.1 첫번째 시도</a></li>
<li><a href="#3-2-두번째-시도">3.2 두번째 시도</a></li>
</ul></li>
<li><a href="#4-파라미터-찾기">4 파라미터 찾기</a>
<ul>
<li><a href="#4-1-gradient-descent">4.1 Gradient descent</a></li>
<li><a href="#4-2-파이썬-코드">4.2 파이썬 코드</a></li>
</ul></li>
<li><a href="#5-참고-자료">5 참고 자료</a></li>
</ul></li>
</ul>
</nav>
    </div>
</div>

          </div>
        
        
        <div id="body-inner">
          
            <h1>ML03 - 로지스틱 회귀</h1>
          






<h2 id="1-문제를-정의하기">1 문제를 정의하기</h2>

<h3 id="1-1-데이터-세트">1.1 데이터 세트</h3>

<p>이해를 돕기 위하여 다음과 같이 두 종류의 데이터 세트를 준비하고 결과를 비교해 봅니다.</p>

<ul>
<li>DS-A:</li>
</ul>

<p>$$x=\left[ 1,2,3,4,5,6,7,8,9,10 \right] ,\quad y=[0,0,0,0,0,1,1,1,1,1]$$</p>

<ul>
<li>DS-B:</li>
</ul>

<p>$$x=\left[ 1,2,3,4,5,6,7,8,9,10 \right] ,\quad y=[0,0,0,0,1,0,1,1,1,1]$$</p>

<p>위에서 x는 독립 변수이고 y는 종속 변수입니다. y는 0 또는 1을 값으로 가집니다.</p>

<p><img src="/ml/ml03-datasets.png" alt="Datasets" /></p>

<h3 id="1-2-단계별로-과제-해결">1.2 단계별로 과제 해결</h3>

<p>아래에서 제시하는 단계별로 과제를 해결합니다.</p>

<ol>
<li>데이터 세트를 잘 나타내는 hypothesis를 찾습니다.</li>
<li>데이터 세트의 y값과 hypothesis의 예측값의 차이를 나타내는 cost function을 정의합니다.</li>
<li>각각의 데이터 세트에 대하여 cost를 최소화하는 hypothesis의 파라미터를 찾습니다.</li>
</ol>

<p>이렇게 얻은 hypothesis를 사용하여 새로운 데이터의 y값을 예측합니다.</p>

<h2 id="2-hypothesis-찾기">2 Hypothesis 찾기</h2>

<p>다음은 hypothesis를 정의하는데 도움이 될만한 데이터 세트의 특성입니다.</p>

<ol>
<li>데이터의 x값에 따라 y값이 0과 1로 구분됩니다.</li>
<li>x값이 어떤 임계값보다 작을 때는 y값이 0, 크면 y값이 1이라고 말할 수 있습니다.</li>
<li>y값이 0인 데이터와 1인 데이터의 x값이 서로 겹치는 범위가 데이터 세트에 따라 매우 좁을 수도 있고 넓을 수도 있습니다.</li>
</ol>

<p>이러한 특성을 고려하여 다음과 같은 의미를 가지는 hypothesis를 찾고자 합니다.</p>

<p>$$p(y=1|x;w)$$</p>

<p>위 표현은 파라미터 w가 정해지고 x값이 주어질 때 y값이 1일 가능성을 의미합니다. p가 가지는 값의 범위는 $0 \sim 1$입니다. p의 값이 0.5 이상이면 y값이 1, 0.5 미만이면 y값이 0이라고 판정합니다.</p>

<h3 id="2-1-첫번째-시도">2.1 첫번째 시도</h3>

<p>다음과 같이 hypothesis는 x의 1차식이라고 가정해 봅니다.</p>

<p>$${ h }_{ w }(x)=w_0+w_1x$$</p>

<p>그러면 $h_w(x)$가 가질 수 있는 값의 범위는 $-\infty \sim +\infty $가 되어 찾고자 하는 hypothesis가 될 수 없습니다.</p>

<h3 id="2-2-두번째-시도">2.2 두번째 시도</h3>

<p>x의 일차식은 단조증가하거나 단조감소합니다. 따라서 좌변은 이러한 조건을 만족시키는 $h_w(x)$의 함수식이어야 합니다. <strong>y=0일 가능성 대비 y=1일 가능성의 비율</strong>이 단조증가하므로 hypothesis를 다음과 같이 가정해 봅니다.</p>

<p>$$\frac {h_w(x)}{1 - h_w(x)}=w_0+w_1x$$</p>

<p>하지만 $h_w(x)$가 $0 \sim 1$ 사이의 값을 가질 때 좌변이 가질 수 있는 값의 범위는 $0 \sim +\infty$로 여전히 우변이 가질 수 있는 값의 범위와 일치하지 않습니다.</p>

<p>참고로 <strong>y=0일 가능성 대비 y=1일 가능성의 비율</strong>을 <strong>odds ratio</strong>라고 부릅니다.</p>

<p>$$odds(p) = \frac {p} {1-p} =\frac {성공할 \quad 가능성} {실패할 \quad 가능성}$$</p>

<h3 id="2-3-세번째-시도">2.3 세번째 시도</h3>

<p>값의 범위가 $0 \sim +\infty$일 때 로그를 적용하면 단조증가하면서 값의 범위가 $-\infty \sim +\infty$로 확장됩니다. 그래서 이번에는 좌변에 로그를 적용해 봅니다.</p>

<p>$$log(\frac {h_w(x)}{1 - h_w(x)})=w_0+w_1x$$</p>

<p>Odds ratio에 로그를 적용한 것을 <strong>로지스틱(logistic) 함수</strong>라고 부릅니다.</p>

<p>이제 좌변과 우변 모두 동일한 값의 범위를 가지도록 하는 방법을 찾았습니다. 위 식을 hypothesis에 대하여 풀면 다음과 같습니다.</p>

<p>$$h_w(x)=\frac {1} {1+{ e }^{ -(w_0 + w_1x) }}$$</p>

<p>$x_0=1$이라고 정의하면 위 수식은 다음과 같이 표현할 수 있습니다.</p>

<p>$$w=(w_0,w_1), \quad x=(x_0,x_1)$$
$$w_0x_0 + w_1x_1 = w^Tx = z(x)$$
$$h_w(x)=\frac {1} {1+{ e }^{ -z(x) }}$$</p>

<p>이러한 형태의 함수를 그래프로 그려 보면 S자 모양과 비슷하며 <strong>시그모이드(sigmoid) 함수</strong>라고 부릅니다.</p>

<p>여기서 눈여겨 볼 것은 좌변에서 사용할 $h_w(x)$의 함수식을 찾을 때 다음 두 가지를 만족시킬 수 있다면 logit 함수가 아니어도 된다는 사실입니다.</p>

<ul>
<li>단조증가 또는 단조감소</li>
<li>값의 범위가 $-\infty \sim +\infty $</li>
</ul>

<div class="alert 
	alert-info"
 
role="alert">문제: logit 함수가 아닌 $h_w(x)$의 함수식을 찾아 보시오.</div>


<h2 id="3-cost-function-정의하기">3 Cost function 정의하기</h2>

<p>선형 회귀에서와 같이 최소자승법을 사용하여 비용 함수를 정의하면 non-convex 함수가 되어 최소값을 찾는 것이 어려워집니다.</p>

<p>$$J(w)=\frac { 1 }{ m } \sum _{ i=1 }^{ m } \frac {1} {2} { (h_w(x^{(i)}) - y^{(i)})^2 }$$</p>

<p>그래서 convex 함수가 되도록 비용 함수를 정의해 보고자 합니다.</p>

<p>$$J(w)=\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ Cost(h_w(x^{(i)}), y^{(i)}) }$$</p>

<h3 id="3-1-첫번째-시도">3.1 첫번째 시도</h3>

<p>개별 데이터에 대한 비용을 계산할 때 사용할 수식을 아래와 같이 정의하면 데이터 세트에 대한 비용 함수는 convex 형태가 됩니다.</p>

<p>$$Cost(h_{ w }(x^{ (i) }),y^{ (i) })=\quad \quad h_w(x^{(i)}), \quad for \quad y^{(i)}=0 $$</p>

<p>$$Cost(h_{ w }(x^{ (i) }),y^{ (i) })=1 - h_w(x^{(i)}), \quad for \quad y^{(i)}=1 $$</p>

<p>이것을 하나의 식으로 표현하면 다음과 같습니다.</p>

<p>$$Cost(h_{ w }(x^{ (i) }),y^{ (i) })=(1-y^{(i)}) h_w(x^{(i)}) + y^{(i)}(1-h_w(x^{(i)})$$</p>

<p>위의 정의에 따르면 y값이 0일 때 예측값이 1이 될 가능성이 0에 가까워지면 비용이 줄어들고, 1에 가까워지면 비용이 늘어나게 됩니다. 마찬가지로 y값이 1일 때 예측값이 1이 될 가능성이 0에 가까워지면 비용이 늘어나고 1에 가까워지면 비용이 줄어듭니다. 따라서 비용 함수를 위와 같이 정의하는 것이 타당하다고 할 수 있습니다.</p>

<h3 id="3-2-두번째-시도">3.2 두번째 시도</h3>

<p>그런데 log를 사용하면 수학적으로 더 편리할뿐만 아니라 gradient descent 방식으로 최소값을 찾을 때 더 빠른 속도로 최소값에 접근하게 됩니다. 그래서 log를 사용해서 비용 함수를 다시 정의하면 다음과 같습니다.</p>

<p>$$Cost(h_{ w }(x^{ (i) }),y^{ (i) }) = -log(1-h_w (x^{(i)})), \quad {for} \quad y^{(i)} = 0$$</p>

<p>$$Cost(h_{ w }(x^{ (i) }),y^{ (i) }) = \quad \quad -log(h_w (x^{(i)})), \quad {for} \quad y^{(i)} = 1$$</p>

<p>이것을 하나의 식으로 표현하면 다음과 같습니다.</p>

<p>$$Cost(h_{ w }(x^{ (i) }),y^{ (i) })=-y^{(i)} log(h_w(x^{(i)})) - (1-y^{(i)})log(1-h_w(x^{(i)})$$</p>

<p>첫번째 시도에서 얻은 비용 함수와 비교해 보면 y값이 0일 때 예측값이 1이 될 가능성이 1에 가까워지면 비용이 훨씬 더 가파르게 증가합니다. gradient descent 방식에서는 경사가 심할수록 더 빠른 속도로 최소값에 접근합니다.</p>

<p>이제 하나의 데이터 세트에 대한 비용 함수를 다음과 같이 표현할 수 있습니다.</p>

<p>$$J(w)=\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \left[ -y^{(i)} log(h_w(x^{(i)})) - (1-y^{(i)})log(1-h_w(x^{(i)}) \right]}$$</p>

<h2 id="4-파라미터-찾기">4 파라미터 찾기</h2>

<h3 id="4-1-gradient-descent">4.1 Gradient descent</h3>

<p>비용 함수의 편미분을 사용하여 비용을 최소화하는 파라미터 w를 찾을 수 있습니다. 다음은 gradient descent 방식을 나타내는 알고리즘입니다.</p>

<div>$$
repeat \quad \{ \quad \quad \quad \quad \quad \quad \quad \quad\\

{ w }_{ j }:={ w }_{ j }-\alpha \frac { \partial J(w) }{ \partial { w }_{ j } } \\

\} \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad
$$</div>

<div>$$
\frac { \partial J(w) }{ \partial { w }_{ j } } =\frac { 1 }{ m } \sum _{ i=1 }^{ m }{ \left( { h }_{ w }({ x }^{ (i) })-{ y }^{ (i) } \right) { { x }_{ j } }^{ (i) } } 
$$</div>

<p>위의 식에서 $\alpha$는 학습률(learning rate)입니다.</p>

<h3 id="4-2-파이썬-코드">4.2 파이썬 코드</h3>

<p>아래 링크는 실습을 위해 작성한 파이썬 노트북입니다.</p>

<ul>
<li><a href="https://github.com/trvoid/ml-study/blob/master/ML03-LogisticRegression.ipynb">ML03-로지스틱 회귀</a></li>
</ul>

<h2 id="5-참고-자료">5 참고 자료</h2>

<ol>
<li><a href="http://karlrosaen.com/ml/notebooks/logistic-regression-why-sigmoid/">The Sigmoid Function in Logistic Regression</a> by Karl Rosaen</li>
<li><a href="http://www.theanalysisfactor.com/what-is-logit-function/">What is a Logit Function and Why Use Logistic Regression?</a> by KAREN GRACE-MARTIN</li>
</ol>


<footer class=" footline" >
	
</footer>



      </div>
    </div>

    
 
    

    <div id="navigation">
        
        
        
        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
            
        
        
        


        
            <a class="nav nav-prev" href="/ml/ml02-linear-regression/" title="ML02 - 선형 회귀"> <i class="fa fa-chevron-left"></i></a>
        
        
            <a class="nav nav-next" href="/web/" title="Web" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
        
    </div>

    
    <div id="disqus_thread" class="padding"></div>
      
    
    </section>
    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="/js/clipboard.min.js"></script>
    <script src="/js/featherlight.min.js"></script>
    <script src="/js/html5shiv-printshiv.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="/js/modernizr.custom.71422.js"></script>
    <script src="/js/learn.js"></script>
    <script src="/js/hugo-learn.js"></script>

    
    <link href="/mermaid/mermaid.css" type="text/css" rel="stylesheet"/>
    <script src="/mermaid/mermaid.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    
    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],
                       displayMath: [['\\[','\\]'], ['$$','$$']]}});
    </script>
    
    
    
    <script>
      

      

      (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://trvoid.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      

    

  </body>
</html>

